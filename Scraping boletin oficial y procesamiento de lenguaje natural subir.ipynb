{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para hacer scraping de la página del Boletín oficial (búsqueda avanzada)\n",
    "#Selenium es un conjunto de herramientas de software de código abierto utilizado para la \n",
    "#automatización de pruebas funcionales en aplicaciones web. Selenium proporciona una \n",
    "#interfaz de programación de aplicaciones (API) para controlar un navegador web y simular \n",
    "#la interacción humana con una página web.\n",
    "\n",
    "#Importar librerías\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "#Lista vacía\n",
    "dfs = []\n",
    "\n",
    "# configurar el webdriver\n",
    "service = Service('./chromedriver')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# abrir la página web\n",
    "driver.get(\"https://www.boletinoficial.gob.ar/busquedaAvanzada/primera\")\n",
    "\n",
    "#Definir temas a buscar (en el campo palabra clave). La idea es buscar por tema, sin definir tipo de norma\n",
    "temas= ['precios'\n",
    "        , 'multas'\n",
    "        , 'agio'\n",
    "        , 'especulación'\n",
    "        , 'abastecimiento'\n",
    "#        , 'inflación'\n",
    "       ]\n",
    "\n",
    "#Definir años de búsqueda\n",
    "año_inicio = 1900\n",
    "año_fin = 1976\n",
    "años = list(range(año_inicio, año_fin))\n",
    "años = list(map(str, años))\n",
    "\n",
    "# buscar elementos \n",
    "#itera sobre los temas\n",
    "for j in temas:\n",
    "    #Para cada tema, si lo encuentra, intenta iterar sobre los años\n",
    "    for i in años:\n",
    "    \n",
    "        # Cambo de búsqueda palabra clave\n",
    "        search_box1 = driver.find_element(By.ID, \"palabraClave\")\n",
    "        search_box1.send_keys(j)\n",
    "\n",
    "        # Cambo de búsqueda palabra año\n",
    "        search_box2 = driver.find_element(By.ID, \"anioNormaIP\")\n",
    "        search_box2.send_keys(i)\n",
    "     \n",
    "        try:\n",
    "            # hacer clic en el botón de búsqueda\n",
    "            search_button = WebDriverWait(driver, 25).until(EC.presence_of_element_located((By.ID, \"btnBusquedaAvanzada\")))\n",
    "            search_button.click()\n",
    "            \n",
    "            # espera a que se carguen nuevos resultados (1 segundo)\n",
    "            time.sleep(1)\n",
    "            \n",
    "            # limpiar ambos campos de entrada\n",
    "            search_box1.clear()\n",
    "            search_box2.clear()\n",
    "           \n",
    "            \n",
    "            # hacer scroll hasta el final de la página\n",
    "            while True:\n",
    "                # obtener número actual de resultados\n",
    "                num_resultados = len(driver.find_elements(By.XPATH, \"//div[@class='list-group-item list-group-item-action flex-column align-items-start']\"))\n",
    "    \n",
    "                # hacer scroll hasta el final de la página\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    \n",
    "                # esperar a que se carguen nuevos resultados (2 segundos)\n",
    "                time.sleep(2)\n",
    "    \n",
    "                # obtener nuevo número de resultados\n",
    "                num_nuevos_resultados = len(driver.find_elements(By.XPATH, \"//div[@class='list-group-item list-group-item-action flex-column align-items-start']\"))\n",
    "    \n",
    "                # salir del bucle si no hay más resultados nuevos\n",
    "                if num_nuevos_resultados == num_resultados:\n",
    "                    break\n",
    "\n",
    "            # extraer resultados visibles\n",
    "            resultados = driver.find_elements(By.XPATH, \"//div[contains(@class, 'col-md-12') and @class!='row']\")\n",
    "\n",
    "            #Busca el elemento \"8\" entre los resultados, que es el que contiene toda la normativa\n",
    "            normas = resultados[8].text\n",
    "            #Separa la gran string de normas en una lista\n",
    "            lista_normas = normas.split('\\n')\n",
    "\n",
    "            #Se eliminan de la lista los elementos que indican los tipos de normas que siguen\n",
    "            for item in ['LEYES', 'DECRETOS', 'RESOLUCIONES', 'DISPOSICIONES', \n",
    "                         'RESOLUCIONES GENERALES', 'RESOLUCIONES CONJUNTAS', 'AVISOS OFICIALES']:\n",
    "                if item in lista_normas:\n",
    "                    lista_normas.remove(item)\n",
    "            \n",
    "            #Se crean 4 columnas con los 4 elementos de cada norma\n",
    "            original = lista_normas\n",
    "            n = 4\n",
    "            sublistas = []\n",
    "\n",
    "            for i in range(0, len(original), n):\n",
    "                sublistas.append(original[i:i+n])\n",
    "\n",
    "            # Crear la lista de listas\n",
    "            lista_de_listas = sublistas\n",
    "\n",
    "            # Crear el DataFrame\n",
    "            df = pd.DataFrame(data=lista_de_listas, columns=['Poder', 'Norma', 'Fecha', 'Contenido'])\n",
    "            df['tema'] = j\n",
    "\n",
    "            dfs.append(df)\n",
    "        \n",
    "        except:\n",
    "            # si no se encuentra la palabra clave, pasar a la siguiente iteración sin generar un mensaje de error\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crea un dataframe con las normas ya divididas en 4 columnas\n",
    "dfs_concatenado = pd.concat(dfs)\n",
    "dfs_concatenado = dfs_concatenado.reset_index()\n",
    "dfs_concatenado = dfs_concatenado.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procesamiento de lenguaje natural con spacy\n",
    "#SpaCy es una biblioteca de procesamiento del lenguaje natural (NLP) \n",
    "#de código abierto para Python. SpaCy se utiliza para realizar tareas \n",
    "#de procesamiento de texto, como tokenización, análisis sintáctico, \n",
    "#etiquetado POS (partes del habla), reconocimiento de entidades nombradas, \n",
    "#desambiguación de sentidos, entre otras.\n",
    "\n",
    "#SpaCy también cuenta con modelos pre-entrenados para varios idiomas, \n",
    "#incluidos inglés, español, alemán, francés, portugués, italiano y holandés, \n",
    "#lo que permite a los usuarios realizar tareas de NLP sin necesidad de entrenar modelos desde cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isnan\n",
    "from unidecode import unidecode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo de lenguaje en español\n",
    "nlp = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Definir función para analizar texto\n",
    "def analizar_texto(texto):\n",
    "    doc = nlp(texto)\n",
    "    #usar el modelo para extraer diversas entidades del resumen del contenido de cada norma \n",
    "    #Obtener sustantivos y nombres propios, verbos y adjetivos\n",
    "    sustantivos_y_nombres_propios = [token.lemma_ for token in doc if token.pos_ in ['NOUN', 'PROPN']]\n",
    "    verbos = [token.lemma_ for token in doc if token.pos_ == 'VERB']\n",
    "    adjetivos = [token.text for token in doc if token.pos_ == 'ADJ']\n",
    "    # Encontrar caracteres numéricos \n",
    "    #(que normalmente representan otras normas a las que hace referencia la que estamos analizando)\n",
    "    numeros = [token.text for token in doc if token.is_digit]\n",
    "    return sustantivos_y_nombres_propios, verbos, adjetivos, numeros\n",
    "\n",
    "#crear 4 columnas nuevas con las distintas entidades aplicando la función a la columna 'contenido' \n",
    "dfs_concatenado['Contenido'].fillna('', inplace=True)\n",
    "dfs_concatenado[['sustantivos_y_nombres_propios', 'verbos', 'adjetivos', 'numeros']] = pd.DataFrame(dfs_concatenado['Contenido'].apply(analizar_texto).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mejorar algunas columnas\n",
    "dfs_concatenado[['Norma', 'Año']] = dfs_concatenado['Norma'].str.split('/', n=1, expand=True)\n",
    "dfs_concatenado[['Norma', 'Número']] = dfs_concatenado['Norma'].str.split(' ', n=1, expand=True)\n",
    "dfs_concatenado['Fecha'] = dfs_concatenado['Fecha'].str.replace('Fecha de Publicacion: ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_concatenado[\"Año\"] = dfs_concatenado[\"Año\"].str.replace(\"N/\", \"\")\n",
    "dfs_concatenado[\"Año\"] = dfs_concatenado[\"Año\"].str.replace(\"n/\", \"\")\n",
    "\n",
    "dfs_concatenado['Año'] = pd.to_numeric(dfs_concatenado['Año'] , errors='coerce').astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardar dataset con información categorizada de normas de diversos temas y \n",
    "#con la amplitud de fechas que queramos\n",
    "\n",
    "dfs_concatenado.to_excel('normas.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## FIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
